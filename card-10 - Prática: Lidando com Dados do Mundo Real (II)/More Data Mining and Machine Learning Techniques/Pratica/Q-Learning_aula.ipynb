{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a17a9945-4dc5-4a04-9f93-a4245700e5e3",
   "metadata": {},
   "source": [
    "# Reinforcement Learning\n",
    "Let's describe the \"taxi problem\". We want to build a self-driving taxi that can pick up passengers at one of a set of fixed locations, drop them off at another location, and get there in the quickest amount of time while avoiding obstacles.\n",
    "\n",
    "The AI Gym lets us create this environment quickly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e72a69da-6924-4445-8040-e113fe2ce043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|R: | : :\u001b[34;1m\u001b[43mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import gym # importa o gym\n",
    "import random # importa o random\n",
    "\n",
    "random.seed(1234)\n",
    "\n",
    "streets = gym.make(\"Taxi-v3\").env\n",
    "streets.reset()\n",
    "print(streets.render())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c478ac-4dc9-4f99-84dc-2bac6824a933",
   "metadata": {},
   "source": [
    "Let's break down what we're seeing here:\n",
    "\n",
    "- R, G, B, and Y are pickup or dropoff locations.\n",
    "- The BLUE letter indicates where we need to pick someone up from.\n",
    "- The MAGENTA letter indicates where that passenger wants to go to.\n",
    "- The solid lines represent walls that the taxi cannot cross.\n",
    "- The filled rectangle represents the taxi itself - it's yellow when empty, and green when carrying a passenger.\n",
    "\n",
    "Our little world here, which we've called \"streets\", is a 5x5 grid. The state of this world at any time can be defined by:\n",
    "\n",
    "- Where the taxi is (one of 5x5 = 25 locations)\n",
    "- What the current destination is (4 possibilities)\n",
    "- Where the passenger is (5 possibilities: at one of the destinations, or inside the taxi)\n",
    "\n",
    "So there are a total of 25 x 4 x 5 = 500 possible states that describe our world.\n",
    "\n",
    "For each state, there are six possible actions:\n",
    "\n",
    "- Move South, East, North, or West\n",
    "- Pickup a passenger\n",
    "- Drop off a passenger\n",
    "\n",
    "Q-Learning will take place using the following rewards and penalties at each state:\n",
    "\n",
    "- A successfull drop-off yields +20 points\n",
    "- Every time step taken while driving a passenger yields a -1 point penalty\n",
    "- Picking up or dropping off at an illegal location yields a -10 point penalty\n",
    "- Moving across a wall just isn't allowed at all.\n",
    "\n",
    "Let's define an initial state, with the taxi at location (2, 3), the passenger at pickup location 2, and the destination at location 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e630d29-69d1-418d-9766-0fc1d61dd373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : | : : |\n",
      "| : : :\u001b[43m \u001b[0m: |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "initial_state = streets.encode(2, 3, 2, 0) # define o estado inicial do taxi\n",
    "\n",
    "streets.s = initial_state # define o estado inicial\n",
    "\n",
    "streets.render() # renderiza o ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cee3bd6-a8cd-482d-951d-746de2212f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [(1.0, 368, -1, False)],\n",
       " 1: [(1.0, 168, -1, False)],\n",
       " 2: [(1.0, 288, -1, False)],\n",
       " 3: [(1.0, 248, -1, False)],\n",
       " 4: [(1.0, 268, -10, False)],\n",
       " 5: [(1.0, 268, -10, False)]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streets.P[initial_state]\n",
    "# o dicionário abaixo mostra as possíveis ações que o taxi pode tomar em cada estado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab6f8a6-129c-48a7-8eed-8708990a2bec",
   "metadata": {},
   "source": [
    "Here's how to interpret this - each row corresponds to a potential action at this state: move South, North, East, or West, pickup, or dropoff. The four values in each row are the probability assigned to that action, the next state that results from that action, the reward for that action, and whether that action indicates a successful dropoff took place.\n",
    "\n",
    "So for example, moving North from this state would put us into state number 368, incur a penalty of -1 for taking up time, and does not result in a successful dropoff.\n",
    "\n",
    "So, let's do Q-learning! First we need to train our model. At a high level, we'll train over 10,000 simulated taxi runs. For each run, we'll step through time, with a 10% chance at each step of making a random, exploratory step instead of using the learned Q values to guide our actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3406993-54e8-4b51-910e-c4be2e454750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "q_table = np.zeros([streets.observation_space.n, streets.action_space.n]) # cria a q_table que no caso é uma matriz de zeros \n",
    "\n",
    "learning_rate = 0.1 # indica quanto o agente aprende a cada iteração\n",
    "discount_factor = 0.6 # fator de desconto\n",
    "exploration = 0.1 # chance de escolher uma ação aleatória ao invés da melhor ação\n",
    "epochs = 10000 # número de iterações\n",
    "\n",
    "for taxi_run in range(epochs):\n",
    "    state = streets.reset() # reseta o ambiente\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        random_value = random.uniform(0, 1) # gera um valor aleatório entre 0 e 1 \n",
    "        if (random_value < exploration): # condição para explorar\n",
    "            action = streets.action_space.sample()  \n",
    "        else:\n",
    "            action = np.argmax(q_table[state])\n",
    "        \n",
    "        next_state, reward, done, info, = streets.step(action)\n",
    "        # a função step executa a ação escolhida e retorna o próximo estado\n",
    "\n",
    "        prev_q = q_table[state, action] # valor de q do estado anterior\n",
    "        next_max_q = np.max(q_table[next_state]) # valor de q do próximo estado\n",
    "        new_q = (1 - learning_rate) * prev_q + learning_rate * (reward + discount_factor * next_max_q) # calcula o novo valor de q para o estado atual \n",
    "        q_table[state, action] = new_q # atualiza o valor de q na q_table\n",
    "\n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5522040-3469-4437-a646-afa1518f8a18",
   "metadata": {},
   "source": [
    "So now we have a table of Q-values that can be quickly used to determine the optimal next step for any given state! Let's check the table for our initial state above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c02af8d5-3e70-41c3-96e0-46226fd3efff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.38438861, -2.40342946, -2.42231272, -2.3639511 , -8.9724024 ,\n",
       "       -7.31330384])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table[initial_state]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fb0a6b-90f5-406e-b039-7f2ffe8256bc",
   "metadata": {},
   "source": [
    "The lowest q-value here corresponds to the action \"go West\", which makes sense - that's the most direct route toward our destination from that point. It seems to work! Let's see it in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987c2795-2f26-46e5-bfbe-27352ef2a675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trip number 4\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[34;1m\u001b[43mG\u001b[0m\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "\n",
    "# permite visualizar o taxi se movendo no ambiente\n",
    "for tripnum in range(1, 11):\n",
    "    state = streets.reset()\n",
    "   \n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        action = np.argmax(q_table[state])\n",
    "        next_state, reward, done, info, = streets.step(action)\n",
    "        clear_output(wait=True)# Limpa a tela anterior (para animação suave)\n",
    "        print(\"Trip number \" + str(tripnum))\n",
    "        # Renderiza e imprime o estado visual do ambiente\n",
    "        # mode='ansi' retorna uma string com representação ASCII do ambiente\n",
    "        print(streets.render(mode= 'ansi'))\n",
    "        sleep(.5)\n",
    "          # Atualiza o estado atual para o próximo estado\n",
    "        state = next_state\n",
    "        \n",
    "    # Pausa de 2 segundos entre viagens\n",
    "    sleep(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (conda-base)",
   "language": "python",
   "name": "conda-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
